{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Improving Performance\n",
      "\n",
      "This notebook will\n",
      "\n",
      " - introduce parallel computing with IPython,\n",
      " - cross-validate in parallel,\n",
      " - introduce `numexpr` for improving the efficiency of `numpy`,\n",
      " - improve the efficiency of the FFT with `PyFFTW`,\n",
      " - implement this all in the `FastMKSRegressionModel` class and\n",
      " - run a full Cahn-Hilliard probelm with the `FastMKSRegressionModel`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "%load_ext autoreload\n",
      "%autoreload 2\n",
      "\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "\n",
      "from pymks import MKSRegressionModel\n",
      "from pymks import FastMKSRegressionModel\n",
      "from pymks import FiPyCHModel\n",
      "from sklearn import metrics\n",
      "from sklearn.grid_search import GridSearchCV\n",
      "from pymks import FastMKSRegressionModel\n",
      "import numexpr\n",
      "\n",
      "mse = metrics.mean_squared_error"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Check the number of processors."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%bash\n",
      "\n",
      "cat /proc/cpuinfo | grep processor"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Nproc = 8"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Start up the IPython engines on the local machine using\n",
      "\n",
      "    $ ipcluster start -n 8"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Parallel Data Generation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Generate a large(r) amount of data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.random.seed(101)\n",
      "X = np.random.random((1000, 21, 21))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Create a function to be run on each processor. The `FiPyCHModel` is imported on each processor as it can't be pickled."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def fipymodel_(X):\n",
      "    from pymks import FiPyCHModel\n",
      "    fipymodel = FiPyCHModel()\n",
      "    return fipymodel.predict(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Create a \"direct view\" of the engines."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.parallel import Client\n",
      "rc = Client()\n",
      "dview = rc[:]\n",
      "print \"engines IDs\",rc.ids"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Pass the `fipymodel` function to the engines and scatter the data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dview['fipymodel_'] = fipymodel_\n",
      "dview.scatter('X', X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Perfom the calculation in parallel."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%px y = fipymodel_(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `map_sync` function returns a list which needs to be concatenated into one array."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = dview.gather('y').result\n",
      "print y.dtype\n",
      "print y.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Parallel Cross-validation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Partition the data into training and test arrays."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import train_test_split\n",
      "\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Create a dictionary of tuning parameters to search and define the optimization function."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getScores(Nbins):\n",
      "    from pymks import MKSRegressionModel\n",
      "    from sklearn import metrics\n",
      "    from sklearn.grid_search import GridSearchCV\n",
      "    tuning_parameters = [{'Nbin': Nbins}]\n",
      "    \n",
      "    gridSearch = GridSearchCV(MKSRegressionModel(Nbin=10), tuning_parameters, cv=5,\n",
      "                              score_func=neg_mse)\n",
      "    gridSearch.fit(X_train, y_train)\n",
      "    return gridSearch.grid_scores_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Perform the grid search in parallel."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def neg_mse(a, b):\n",
      "    from sklearn import metrics\n",
      "    mse = metrics.mean_squared_error\n",
      "    return mse(a, b)\n",
      "\n",
      "dview['X_train'] = X_train\n",
      "dview['y_train'] = y_train\n",
      "dview['neg_mse'] = neg_mse\n",
      "dview['getScores'] = getScores\n",
      "\n",
      "grid_scores = dview.map_sync(lambda Nbins: getScores(Nbins), np.array_split(np.arange(2, 20), len(rc.ids)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for gs in grid_scores:\n",
      "    for params, mean_score, scores in gs:\n",
      "        print(\"%1.3e (+/-%1.3e) for %r\"% (mean_score, scores.std() / 2, params))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Exercise 06-0\n",
      "\n",
      "Use the load balanced view to improve the efficiency of parallel cross-validation."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Evaluate the mean square error while varying Nspace in parallel (todo)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Numexpr"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The [Numexpr](http://code.google.com/p/numexpr/) package speeds up `numpy` calculations considerably. For example, take the following"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.random.seed(102)\n",
      "a = np.random.random(1e7)\n",
      "b = np.random.random(1e7)\n",
      "c = np.random.random(1e7)\n",
      "a.dtype"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `%timeit` magic implicitly handles a number of common pit falls when timing Python expression execution."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "?%timeit"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Use `timeit` to time a regular Numpy calculation."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "d = a**2 + b**2 + 2*a*b\n",
      "%timeit a**2 + b**2 + 2*a*b"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Numpy calculations are quite slow when compared with the same code in\n",
      "C. This is due to the overhead from memory allocation for the intermediate arrays."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Use `timeit` to time a [`numexpr`](http://code.google.com/p/numexpr/) calculation."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "e = numexpr.evaluate('a**2 + b**2 + 2 * a * b')\n",
      "%timeit e = numexpr.evaluate('a**2 + b**2 + 2 * a * b')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.all(d == e)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There is no benefit for small expressions with no intermediate memory allocation."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit a**2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "numexpr.set_num_threads(1)\n",
      "%timeit numexpr.evaluate(\"a**2\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[Numexpr](http://code.google.com/p/numexpr/) uses multithreading by default."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for Nthread in range(1, Nproc + 1):\n",
      "    print \"number of threads:\",Nthread\n",
      "    numexpr.set_num_threads(Nthread)\n",
      "    %timeit numexpr.evaluate('a**2 + b**2 + 2 * a * b')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Another example."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit sin(a)**2 + cos(b)**2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit numexpr.evaluate('sin(a)**2 + cos(b)**2')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## PyFFTW"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Using [PyFFTW](Whttp://hgomersall.github.io/pyFFTW/) offers substantial speed ups over Numpy's FFT."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "a = np.random.random((1024, 16384))\n",
      "b_numpy = np.fft.fftn(a, axes=(0, 1))\n",
      "%timeit b_numpy = np.fft.fftn(a, axes=(0, 1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "PyFFTW requires the creation of a \"plan\" in order to optimize the FFT."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pyfftw\n",
      "\n",
      "input_array = pyfftw.n_byte_align_empty(a.shape, 16, 'complex128')\n",
      "output_array = pyfftw.n_byte_align_empty(a.shape, 16, 'complex128')\n",
      "fft_plan = pyfftw.FFTW(input_array, output_array, threads=Nproc, axes=(0, 1), direction='FFTW_FORWARD')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Much faster!"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "input_array[:] = a;\n",
      "b_fftw = fft_plan()\n",
      "%timeit input_array[:] = a; b_fftw = fft_plan()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The return types and values are the same."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print b_fftw.dtype\n",
      "print b_numpy.dtype"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.allclose(b_numpy, b_fftw)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As with Numexpr, threading does help for large arrays."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for Nthread in range(1, Nproc + 1):\n",
      "    fft_plan = pyfftw.FFTW(input_array, output_array, threads=Nthread, axes=(0, 1), direction='FFTW_FORWARD')\n",
      "    print 'Nthread:',Nthread\n",
      "    %timeit input_array[:] = a; b_fftw = fft_plan()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Exercise\n",
      "\n",
      "Identify the bottle necks in the `MKSRegressionModel` using the `line_profiler` and improve things with Numexpr and PyFFTW. Plot the relative speed up versus `Nbin`."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## `FastMKSRegressionModel`\n",
      "\n",
      "Using Numexpr and PyFFTW, we can make improvements to the `MKSRegressionModel`. The `FastMKSRegressionModel` overwrites a number of methods in `MKSRegressionModel`. `FastMKSRegressionModel` only improves the `predict` method, not the `fit` method."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "??FastMKSRegressionModel"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "and it can be tested"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's compare the two classes."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.random.seed(11)\n",
      "X0 = np.random.random((1, 1024, 1024))\n",
      "\n",
      "fast_model = FastMKSRegressionModel(Nbin=5, threads=8)\n",
      "slow_model = MKSRegressionModel(Nbin=5)\n",
      "\n",
      "fast_model.fit(X, y)\n",
      "fast_model.resize_coeff(X0.shape[1:])\n",
      "y_fast = fast_model.predict(X0.copy())\n",
      "\n",
      "slow_model.fit(X, y)\n",
      "slow_model.resize_coeff(X0.shape[1:])\n",
      "y_slow = fast_model.predict(X0.copy())\n",
      "\n",
      "print np.allclose(y_fast, y_slow)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "They give the same result, but what about efficiency gains."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit slow_model.predict(X0.copy())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%timeit fast_model.predict(X0.copy())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This is better for small `Nbin` at the moment. Plot of speed up versus `Nbin`."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Comparing MKS and FiPy"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import clear_output\n",
      "import time\n",
      "from pymks import FiPyCHModel\n",
      "N = 41\n",
      "np.random.seed(13)\n",
      "phi0 = np.random.random((1, N, N))\n",
      "\n",
      "model = FastMKSRegressionModel(Nbin=5)\n",
      "model.fit(X, y)\n",
      "model.resize_coeff((N, N))\n",
      "\n",
      "fig = plt.figure()\n",
      "\n",
      "fipymodel = FiPyCHModel()\n",
      "fipy_phi1 = phi0.copy()\n",
      "mks_phi1 = phi0.copy()\n",
      "steps = 30\n",
      "for i in range(steps):\n",
      "    fipy_response = fipymodel.predict(fipy_phi1)\n",
      "    mks_response = model.predict(mks_phi1)\n",
      "    #Euler forward\n",
      "    fipy_phi1 = fipy_response * fipymodel.dt + fipy_phi1\n",
      "    mks_phi1 = mks_response * fipymodel.dt + mks_phi1\n",
      "    mks_phi1 = np.minimum(mks_phi1, 1)\n",
      "    mks_phi1 = np.maximum(mks_phi1, 0)\n",
      "    #print phi0\n",
      "    plt.subplot(1,2,1)\n",
      "    plt.title('FiPy')\n",
      "    a = plt.imshow(fipy_phi1.reshape((N, N)), vmin=0.0, vmax=1.0)\n",
      "    plt.subplot(1,2,2)\n",
      "    plt.title('MKS')\n",
      "    b = plt.imshow(mks_phi1.reshape((N, N)), vmin=0.0, vmax=1.0)\n",
      "    time.sleep(1)\n",
      "    clear_output()\n",
      "    display(fig)\n",
      "    print i"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Simulation\n",
      "\n",
      "A full simulation. The MKS has to artificially maintain the solution between 0 and 1. This hasn't been fixed yet."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "np.random.seed(11)\n",
      "X0 = np.random.random((1, 256, 256))\n",
      "dt = fipymodel.dt\n",
      "model = FastMKSRegressionModel(Nbin=7, threads=8)\n",
      "model.fit(X, y)\n",
      "model.resize_coeff(X0.shape[1:])\n",
      "data = []\n",
      "X1 = X0.copy()\n",
      "steps = 3000\n",
      "for step in range(steps + 1):\n",
      "    y1 = model.predict(X1)\n",
      "    X1 = numexpr.evaluate('X1 + dt * y1')\n",
      "    X1 = np.minimum(X1, 1)\n",
      "    X1 = np.maximum(X1, 0)\n",
      "    if step % (steps / 200) == 0:\n",
      "        data.append(X1[0])\n",
      "        print step,"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Rudimentary Animation of the Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import clear_output\n",
      "import time\n",
      "\n",
      "fig = plt.figure()\n",
      "ax = plt.axes()\n",
      "a = plt.imshow(X0[0].copy(), vmin=0.0, vmax=1.0)\n",
      "plt.colorbar()\n",
      "for d in data:\n",
      "    a.set_array(d.copy())\n",
      "    plt.show()\n",
      "    time.sleep(1)\n",
      "    clear_output()\n",
      "    display(fig)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Java Script Animation of the Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# JSAnimation import available at https://github.com/jakevdp/JSAnimation\n",
      "from JSAnimation import IPython_display\n",
      "from matplotlib import animation\n",
      "\n",
      "# create a simple animation\n",
      "fig = plt.figure()\n",
      "ax = plt.axes()\n",
      "im = plt.imshow(X0[0], vmin=0.0, vmax=1.0)\n",
      "plt.colorbar()\n",
      "\n",
      "def init():\n",
      "    im.set_array(X0[0])\n",
      "    return im\n",
      "\n",
      "def animate(i):\n",
      "    im.set_array(data[i])\n",
      "    return im\n",
      "\n",
      "anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
      "                               frames=len(data), interval=1, blit=True)\n",
      "\n",
      "from IPython.display import HTML\n",
      "plt.close(anim._fig)\n",
      "HTML(IPython_display.anim_to_html(anim))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Discussion\n",
      "\n",
      " - Why are we getting a reasonable representation of CH with such a low value of `Nbin`?\n",
      " \n",
      " - How can we have an adaptive time step when generating data from an implicit time stepping scheme?\n",
      " \n",
      " - Can we improve the efficiency of `FastMKSRegressionModel` for larger `Nbin`?\n",
      " \n",
      " - Is the mean square error a good metric?"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}