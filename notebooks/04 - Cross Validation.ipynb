{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Cross Validation and Hyperparameter Optimization\n",
      "\n",
      "In this notebook, we will\n",
      " \n",
      " * split the sample data into test and training sets,\n",
      " \n",
      " * optimize the `Nbin` hyperparameter,\n",
      " \n",
      " * learn to use [Sklearn](http://scikit-learn.org) to cross validate the model.\n",
      " "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "%load_ext autoreload\n",
      "%autoreload 2\n",
      "\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "from pymks import MKSRegressionModel\n",
      "from pymks import FiPyCHModel"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Make some actual data (400 samples) with a random seed of 101."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.random.seed(101)\n",
      "X = np.random.random((400, 21, 21))\n",
      "fipymodel = FiPyCHModel()\n",
      "y = fipymodel.predict(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The FiPy Cahn-Hilliard model has been packaged into the `FiPyCHModel` class within the `fit`, `predict` paradigm."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fipymodel.fit(None, None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "??fipymodel"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## A sanity check\n",
      "\n",
      "Let's fit the data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = MKSRegressionModel(Nbin=10)\n",
      "model.fit(X, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `model` now knows its coefficients"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.Fcoeff.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's check that the fit sort of \"looks right\" with one test sample"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.random.seed(102)\n",
      "X_test = np.random.random((1,) + X.shape[1:])\n",
      "y_test = fipymodel.predict(X_test)\n",
      "y_pred = model.predict(X_test)\n",
      "\n",
      "np.random.seed(2)\n",
      "index = np.random.randint(len(y_test.flatten()), size=10)\n",
      "print y_test.flatten()[index]\n",
      "print y_pred.flatten()[index]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "and check the \"mean square error\" using Sklearn's `mean_squared_error` function."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import metrics\n",
      "mse = metrics.mean_squared_error\n",
      "'%1.3e' % np.sqrt(mse(y_test, y_pred))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Seems okay. How do the coefficients look?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "coeff = np.fft.ifftn(model.Fcoeff, axes=(0, 1)).real\n",
      "Nroll = coeff.shape[0] / 2\n",
      "coeff_rolled = np.roll(np.roll(coeff[:,:,0], Nroll, axis=0), Nroll, axis=1)\n",
      "plt.contourf(coeff_rolled, 249)\n",
      "plt.colorbar()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Training and testing\n",
      "\n",
      "Now, let's use the Sklearn function `train_test_split` to split the data into training and test data sets. If we use the entire set\n",
      "of data for the fitting and leave nothing for testing, we have no idea if we are simply \"overfitting\" the data. Think of the analogy of using a high order polynomial\n",
      "to fit data points on a graph, while it may fit the data perfectly, we learn nothing as it is a useless model for fitting subsequently generated data.\n",
      "\n",
      "The argument `test_size=0.5` splits the data into equal sized chunks for training and testing."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.cross_validation import train_test_split\n",
      "\n",
      "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Let's refit with the training data set only."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = MKSRegressionModel(Nbin=10)\n",
      "model.fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "How well does it predict?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'%1.3e' % mse(model.predict(X_test), y_test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The above is just one way to split the data. We may want to check with alternative splits of the data. This is easy using Sklearn's `cross_validation` module. Here we do `10` different splits and check the mean and standard deviation of the mean square error."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import cross_validation\n",
      "\n",
      "model = MKSRegressionModel(Nbin=10)\n",
      "scores = cross_validation.cross_val_score(model, X, y, score_func=mse, cv=10)\n",
      "print(\"MSE: %1.3e (+/- %1.3e)\" % (scores.mean(), scores.std()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `MKSRegressionModel` has methods inherited from the Sklearn's `LinearRegressionModel` that allows the use of `cross_validation`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "??MKSRegressionModel.set_params"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `LinearRegressionModel` may not be the best class to inherit from. Fitting MKS into Sklearn needs careful consideration."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Optimize the `Nbin` hyperparameter\n",
      "\n",
      "`Nbin` is known as a hyperparameter. Hyperparameters are parameters that influence the fitting, but are separate from the data and the parameters used to generate the data.\n",
      "\n",
      "## Exercise 04-0\n",
      "\n",
      "Use all the data (`X` and `y`) to call `fit` for various values of `Nbin`. Calculate the mean square error by comparing the predicted data against the original data, `y`.\n",
      "\n",
      " - Do this for values of `Nbin` starting at 2 up to 100 with spacing of 10 using `np.arange`\n",
      " - What does the graph show?\n",
      " \n",
      "## Exercise 04-1\n",
      "\n",
      "Use the training data (`X_train`, `y_train`) to fit the MKS model and compare it with the test data. Plot the mean square error versus `Nbin`. Do this for all values of `Nbin` between 1 and 20.\n",
      "\n",
      "What is the optimum value of `Nbin`?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Training, validation and test data for hyperparameter optimization\n",
      "\n",
      "Using the test data to optimize hyperparameters leads to test data\n",
      "knowledge leaking into the model. A way to avoid this is to optimize\n",
      "the hyperparamters with a validation data set separate from the test\n",
      "data set. Sklearn provides `GridSearchCV` to automate the optimization\n",
      "of hyperparamters using only the training data without using the test\n",
      "data.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.grid_search import GridSearchCV\n",
      "\n",
      "parameters_to_tune = [{'Nbin': np.arange(2, 20)}]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Make a scoring function. Highest score is best."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def neg_mse(a, b):\n",
      "    return -mse(a, b)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Create a `GridSearchCV` instance."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gridSearch = GridSearchCV(MKSRegressionModel(Nbin=10), parameters_to_tune, cv=5, score_func=neg_mse)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Optimize with only the training data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "??gridSearch.fit"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gridSearch.fit(X_train, y_train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Find the best estimator."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print(gridSearch.best_estimator_)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "What were the MSEs for each value of `Nbin`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for params, mean_score, scores in gridSearch.grid_scores_:\n",
      "    print(\"%1.3e (+/-%1.3e) for %r\"% (mean_score, scores.std() / 2, params))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "How does that match the test data?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y_true, y_pred = y_test, gridSearch.predict(X_test)\n",
      "'%1.3e' % mse(y_true, y_pred)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "What about for other `Nbin`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for Nbin in parameters_to_tune[0]['Nbin']:\n",
      "    model = MKSRegressionModel(Nbin=Nbin)\n",
      "    model.fit(X_train, y_train)\n",
      "    y_true, y_pred = y_test, model.predict(X_test)\n",
      "    print 'Nbin: {0}, mse: {1:1.3e}'.format(Nbin, mse(y_true, y_pred))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Another example from Sklearn's tutorial"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `GridSearchCV` class can be used to search over multiple hyperparameters. This following example is from Sklearn's turorial. The scoring is very different between a classification problem and a "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import datasets\n",
      "\n",
      "digits = datasets.load_digits()\n",
      "\n",
      "print digits.data.shape\n",
      "\n",
      "for index, (image, label) in enumerate(zip(digits.images, digits.target)[:4]):\n",
      "    plt.subplot(2, 4, index + 1)\n",
      "    plt.axis('off')\n",
      "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
      "    plt.title('Training: %i' % label)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import HTML\n",
      "HTML('<iframe src=http://scikit-learn.org/stable/auto_examples/grid_search_digits.html#example-grid-search-digits-py width=700 height=700></iframe>')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "MKS is really prediciting a quantity. The above example is classification."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import Image\n",
      "Image(url='http://scikit-learn.org/stable/_static/ml_map.png', width=900)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}